{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPC/SU/II Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages, Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "\n",
    "#set location for saving files\n",
    "directory = \"C://Users//rorey//OneDrive - Bipartisan Policy Center//Elections Project//Research//BPC SU II Joint Survey Dec 23//programming//files//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = pd.read_csv('https://raw.githubusercontent.com/rachelorey/Dec23-survey/main/2312082_BPC_levels_codebook.csv', encoding='utf-8')\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/rachelorey/Dec23-survey/main/2312082_BPC_raw_data.csv', encoding='utf-8')\n",
    "q_codebook = pd.read_csv('https://raw.githubusercontent.com/rachelorey/Dec23-survey/main/2312082_BPC_question_codebook.csv', encoding='utf-8', index_col = 'qid')\n",
    "\n",
    "# q_codebook into dict\n",
    "q_codebook = q_codebook.to_dict().get('qidFull')\n",
    "\n",
    "# display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldata = pd.DataFrame(data.isnull().sum(),columns=[\"Sum_Null\"]) ##2203 rows in entire dataset\n",
    "nulldata.sort_values(by=[\"Sum_Null\"],ascending=False,inplace=True)\n",
    "\n",
    "# nulldata[nulldata[\"Sum_Null\"]>0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Percents by Demo for Scaled Questions\n",
    "#### BPC21, BPC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_counts(x):\n",
    "    # x is a DataFrame of grouped values including the 'wts' column for weights\n",
    "    total_weight = x['wts'].sum()\n",
    "    return total_weight\n",
    "\n",
    "def getdemo_scaled(demo,q,collapse_scales=False):\n",
    "    # Extracting demo labels\n",
    "    labels = dict(zip(codebook[codebook['question'] == demo]['value'], codebook[codebook['question'] == demo]['code']))\n",
    "\n",
    "    # Filtering out the relevant rows from the codebook for BPCX responses\n",
    "    bpcx_codebook = codebook[codebook['question'].str.contains(q)]\n",
    "\n",
    "    # Creating a dictionary to map response values to their meanings\n",
    "    value_to_meaning = dict(zip(bpcx_codebook['value'], bpcx_codebook['code']))\n",
    "\n",
    "    # List to hold the reshaped tables\n",
    "    long_format_tables = []\n",
    "\n",
    "    # Iterate through each BPCX question\n",
    "    for question in data.filter(regex='^'+q).columns:\n",
    "\n",
    "##ADDING WEIGHTS\n",
    "        # Group by 'demo' and 'question', then apply the weighted counts calculation\n",
    "        summary_table = data.groupby([demo,question]).apply(weighted_counts).unstack()\n",
    "    \n",
    "        # Rename index using the labels dictionary\n",
    "        summary_table = summary_table.rename(index=labels)\n",
    "\n",
    "        # Rename columns using the value_to_meaning dictionary\n",
    "        summary_table = summary_table.rename(columns=value_to_meaning)\n",
    "\n",
    "        # Reset index to make demo a column\n",
    "        summary_table = summary_table.reset_index()\n",
    "\n",
    "        # Melt the DataFrame to long format\n",
    "        melted = summary_table.melt(id_vars=demo, var_name='Response', value_name='Count')\n",
    "        melted['Question'] = question\n",
    "\n",
    "        # Replace the question shorthand with specific concern\n",
    "        melted['Q_Text'] = q_codebook.get(question, question)  # Fallback to question ID if not found\n",
    "\n",
    "        # Append to the list\n",
    "        long_format_tables.append(melted)\n",
    "\n",
    "    # Concatenate all the long format tables into one\n",
    "    combined_long_table = pd.concat(long_format_tables)\n",
    "    try:\n",
    "        combined_long_table[\"Q_Text\"] = combined_long_table[\"Q_Text\"].str.split(' --- ', expand=True)[1].fillna(combined_long_table[\"Q_Text\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    response_mapping = {\n",
    "        'Very concerned': 'Concerned',\n",
    "        'Somewhat concerned': 'Concerned',\n",
    "        'Not too concerned': 'Not Concerned',\n",
    "        'Not at all concerned': 'Not Concerned',\n",
    "        \"Don't know/No opinion\": \"Don't know/No opinion\",\n",
    "        'Very important': 'Important',\n",
    "        'Somewhat important': 'Important',\n",
    "        'Not too important': 'Not important',\n",
    "        'Not at all important': 'Not important',\n",
    "        \"Far too little\":\"Too little\",\n",
    "        \"Far too much\":\"Too much\"        \n",
    "    }\n",
    "    \n",
    "    if collapse_scales: #if function says to collapse scales (ie take out very, somehwat)\n",
    "        if ~combined_long_table[\"Response\"].str.lower().str.contains(\"confident\").any(): #if Response values don't include \"confident\"\n",
    "            # Apply the mapping to collapse response categories\n",
    "            combined_long_table['Response'] = combined_long_table['Response'].map(response_mapping)\n",
    "\n",
    "    # Pivot the table to wide format\n",
    "    wide_format_table = combined_long_table.pivot_table(index=['Q_Text','Response'], \n",
    "                                                        columns=[demo], \n",
    "                                                        values='Count',\n",
    "                                                        fill_value=0)\n",
    "\n",
    "    wide_format_table.reset_index(inplace=True)\n",
    "\n",
    "    for q_level in wide_format_table[\"Q_Text\"].unique():\n",
    "        # Mask for the rows that correspond to the question\n",
    "        question_mask = wide_format_table[\"Q_Text\"] == q_level\n",
    "\n",
    "        # Select the relevant data for the current question\n",
    "        temp = wide_format_table.loc[question_mask, wide_format_table.columns[2:]]\n",
    "\n",
    "        # Calculate the totals for each column (for the current question)\n",
    "        totals = temp.sum()\n",
    "\n",
    "        # Use .loc to update the original dataframe\n",
    "        wide_format_table.loc[question_mask, temp.columns] = temp / totals.values\n",
    "\n",
    "    \n",
    "    # GET TOTAL PERCENTS\n",
    "    \n",
    "    # Get total responses by Q_Text\n",
    "    total_counts = combined_long_table.groupby(['Q_Text'])['Count'].sum().reset_index(name='Total Count')\n",
    "\n",
    "    overall_percent = (combined_long_table.groupby([\"Response\",\"Q_Text\"])['Count'].sum()/combined_long_table.groupby(['Q_Text'])['Count'].sum()[0]).reset_index()\n",
    "    overall_percent.rename({\"Count\":\"Overall\"},axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    wide_format_table = pd.merge(wide_format_table, overall_percent, on=[\"Response\", 'Q_Text'])\n",
    "    \n",
    "    wide_format_table.to_csv(directory+q+\"_\"+demo+\".csv\",index=False)\n",
    "    \n",
    "#     display(wide_format_table)\n",
    "\n",
    "    return(combined_long_table,wide_format_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for q in [\"BPC12\",\"BPC13\",\"BPC14\",\"BPC16\"]:\n",
    "#     getdemo_scaled(\"age\",q,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getdemo_scaled(\"xpid3\",\"BPC7\",False) #BPC7 BPC5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in [\"BPC4\",\"BPC7\"]:\n",
    "#     getdemo_scaled(\"xpid3\",q,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##RUNS FOR ALL CONFIDENCE QUESTIONS\n",
    "\n",
    "# res = pd.DataFrame(columns=['Q_Text', 'Response', 'PID: Dem (no lean)', 'PID: Ind (no lean)','PID: Rep (no lean)','Overall'])\n",
    "\n",
    "# dataframes_to_concat = [res]\n",
    "\n",
    "# for que in [\"BPC17\",\"BPC18\",\"BPC19\",\"BPC20\"]:\n",
    "#     combined_long_table,wide_format_table = getdemo_scaled(\"xpid3\",que,False)\n",
    "#     dataframes_to_concat.append(wide_format_table)\n",
    "\n",
    "# res = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "# res.to_csv(directory+\"BPC17-20.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Percents by Question and Demo for \"Select All That Apply\" Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FUNCTION to get breakdown in responses for \"select all that apply\" question by demo\n",
    "\n",
    "def get_demo_percents(demo,q):\n",
    "\n",
    "    # Extracting political party labels\n",
    "    demo_labels = dict(zip(codebook[codebook['question'] == demo]['value'], codebook[codebook['question'] == demo]['code']))\n",
    "\n",
    "    # Filtering out the relevant rows from the codebook for BPCX responses\n",
    "    bpcx_codebook = codebook[codebook['question'].str.contains(q)]\n",
    "\n",
    "    # Creating a dictionary to map response values to their meanings\n",
    "    value_to_meaning = dict(zip(bpcx_codebook['value'], bpcx_codebook['code']))\n",
    "\n",
    "    # List to hold the reshaped tables\n",
    "    long_format_tables = []\n",
    "\n",
    "    # Iterate through each BPCX question\n",
    "    for question in data.filter(regex='^'+q+\"_\").columns:\n",
    "\n",
    "        ##ADDING WEIGHTS\n",
    "        # Group by 'demo' and 'question', then apply the weighted counts calculation\n",
    "        summary_table = data.groupby([demo,question]).apply(weighted_counts).unstack()\n",
    "\n",
    "        # Rename index using the demo_labels dictionary\n",
    "        summary_table = summary_table.rename(index=demo_labels)\n",
    "\n",
    "        # Rename columns using the value_to_meaning dictionary\n",
    "        summary_table = summary_table.rename(columns=value_to_meaning)\n",
    "\n",
    "        # Reset index to make demo a column\n",
    "        summary_table = summary_table.reset_index()\n",
    "    #     display(summary_table)\n",
    "\n",
    "        # Melt the DataFrame to long format\n",
    "        melted = summary_table.melt(id_vars=demo, var_name='Response', value_name='Count')\n",
    "        melted['Question'] = question\n",
    "    #     display(melted)\n",
    "\n",
    "        # Replace the question shorthand\n",
    "        melted['Q_Text'] = q_codebook.get(question, question)  # Fallback to question ID if not found\n",
    "\n",
    "        # Append to the list\n",
    "        long_format_tables.append(melted)\n",
    "\n",
    "    # Concatenate all the long format tables into one\n",
    "    combined_long_table = pd.concat(long_format_tables)\n",
    "\n",
    "    #remove \"Other\" open-text responses\n",
    "    combined_long_table = combined_long_table[~combined_long_table[\"Question\"].str.contains(\"TEXT\")]\n",
    "\n",
    "    #remove superfluous question text\n",
    "    try:\n",
    "        combined_long_table[\"Q_Text\"] = combined_long_table[\"Q_Text\"].str.split(' --- ', expand=True)[1].fillna(combined_long_table[\"Q_Text\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    combined_long_table.drop([\"Question\"],axis=1,inplace=True)\n",
    "    combined_long_table[\"Response\"] = combined_long_table[\"Response\"].str.replace('NO TEXT',\"Selected\")\n",
    "\n",
    "    ##GET %s\n",
    "\n",
    "    # Group by demo and 'Q_Text', then calculate the sum for each group\n",
    "    total_counts = combined_long_table.groupby([demo, 'Q_Text'])['Count'].sum().reset_index(name='Total Count')\n",
    "\n",
    "    # Filter only 'Selected' responses and calculate the sum\n",
    "    selected_counts = combined_long_table[combined_long_table['Response'] == 'Selected'].groupby([demo, 'Q_Text'])['Count'].sum().reset_index(name='Selected Count')\n",
    "\n",
    "    # Merge the total and selected counts on demo and 'Q_Text'\n",
    "    merged_counts = pd.merge(total_counts, selected_counts, on=[demo, 'Q_Text'])\n",
    "\n",
    "    # Calculate the percentage of 'Selected' for each demo and 'Q_Text'\n",
    "    merged_counts['Selected Percentage'] = (merged_counts['Selected Count'] / merged_counts['Total Count'])\n",
    "    counts = merged_counts[[\"Q_Text\",demo,\"Selected Count\"]]\n",
    "    counts = counts.pivot(index='Q_Text', columns=demo, values='Selected Count').reset_index()\n",
    "    display(counts)\n",
    "#     merged_counts.drop([\"Total Count\",\"Selected Count\"],axis=1,inplace=True)\n",
    "    merged_counts = merged_counts.pivot(index='Q_Text', columns=demo, values='Selected Percentage').reset_index()\n",
    "    \n",
    "    # Get total responses by Q_Text\n",
    "    total_counts = combined_long_table.groupby(['Q_Text'])['Count'].sum().reset_index(name='Total Count')\n",
    "\n",
    "    overall_percent = (combined_long_table.groupby([\"Response\",\"Q_Text\"])['Count'].sum()/combined_long_table.groupby(['Q_Text'])['Count'].sum()[0]).reset_index()\n",
    "    overall_percent.rename({\"Count\":\"Overall\"},axis=1,inplace=True)\n",
    "    \n",
    "    #merge\n",
    "    overall_percent = overall_percent[overall_percent[\"Response\"]==\"Selected\"]\n",
    "    overall_percent.drop([\"Response\"],inplace=True,axis=1)\n",
    "    \n",
    "    merged_counts = pd.merge(merged_counts, overall_percent, on=['Q_Text'])\n",
    "    display(merged_counts)\n",
    "\n",
    "    merged_counts.to_csv(directory+q+\"_\"+demo+\".csv\",index=False)\n",
    "#     counts.to_csv(directory+q+\"_\"+demo+\"_COUNTS.csv\",index=False)\n",
    "    return(combined_long_table,merged_counts,overall_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for q in [\"BPC8\"]:\n",
    "#     combined_long_table,merged_counts,overall_percent = get_demo_percents(\"age\",q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"BPC2\" #\"BPC1\"\n",
    "\n",
    "# for demo in [\"xpid3\",\"age\",\"xdemGender\"]:\n",
    "#     get_demo_percents(demo,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get over all %s (questions with 1 and 2 -- selected/not selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_response_totals(data, column, condition):\n",
    "    \"\"\"Calculate the sum of weights for responses meeting a specific condition.\"\"\"\n",
    "    # Use .loc to ensure the operation is done on the DataFrame, multiplying condition by weights\n",
    "    return (data[column] == condition) * data['wts']\n",
    "\n",
    "def get_total_percents(question):\n",
    "    # Filter columns based on the question prefix\n",
    "    bpc_columns = data.filter(regex='^'+question+'_').columns\n",
    "    \n",
    "    # Initialize dictionaries to store weighted totals and denominators\n",
    "    weighted_totals = {}\n",
    "    weighted_denoms = {}\n",
    "    \n",
    "    # Calculate weighted totals and denominators for each column\n",
    "    for col in bpc_columns:\n",
    "        weighted_totals[col] = get_weighted_response_totals(data, col, 1).sum()\n",
    "        weighted_denoms[col] = get_weighted_response_totals(data, col, 1).sum() + get_weighted_response_totals(data, col, 2).sum()\n",
    "\n",
    "    # Convert dictionaries to DataFrame\n",
    "    BPC = pd.DataFrame(list(weighted_totals.items()), columns=['index', 'total'])\n",
    "    \n",
    "    # Calculate denominators for percentages and add them as a new column\n",
    "    BPC['denominator'] = BPC['index'].map(weighted_denoms)\n",
    "    \n",
    "    # Replace question codes with text descriptions\n",
    "    BPC[\"index\"] = BPC[\"index\"].map(q_codebook)\n",
    "    try:\n",
    "        BPC[\"index\"] = BPC[\"index\"].str.split(' --- ', expand=True)[1].fillna(BPC[\"index\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Calculate percentages\n",
    "    BPC[\"Percent\"] = BPC[\"total\"] / BPC['denominator']\n",
    "    BPC.drop([\"total\",\"denominator\"],axis=1,inplace=True)\n",
    "    \n",
    "    BPC.to_csv(directory+question+\"_overall.csv\",index=False)\n",
    "    \n",
    "    return BPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in [\"BPC1\",\"BPC2\",\"BPC9\"]:\n",
    "#     get_total_percents(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in [\"BPC11\",\"BPC10\"]:\n",
    "#     get_total_percents(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getdemo_scaled(\"xpid3\",\"BPC4\",False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC  - get counts (not percent) for BPC12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_long_table,wide_format_table = getdemo_scaled(\"age\",\"BPC12\",False)\n",
    "\n",
    "# demo='age'\n",
    "\n",
    "# # Pivot the table to wide format\n",
    "# wide_format_table = combined_long_table.pivot_table(index=['Q_Text','Response'], \n",
    "#                                                     columns=[demo], \n",
    "#                                                     values='Count',\n",
    "#                                                     fill_value=0)\n",
    "\n",
    "# wide_format_table.reset_index(inplace=True)\n",
    "\n",
    "# for q_level in wide_format_table[\"Q_Text\"].unique():\n",
    "#     # Mask for the rows that correspond to the question\n",
    "#     question_mask = wide_format_table[\"Q_Text\"] == q_level\n",
    "\n",
    "#     # Select the relevant data for the current question\n",
    "#     temp = wide_format_table.loc[question_mask, wide_format_table.columns[2:]]\n",
    "\n",
    "#     # Calculate the totals for each column (for the current question)\n",
    "#     totals = temp.sum()\n",
    "\n",
    "#     # Use .loc to update the original dataframe\n",
    "# #     wide_format_table.loc[question_mask, temp.columns] = temp / totals.values\n",
    "\n",
    "# wide_format_table.to_csv(directory+\"BPC12counts.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC - BPC3 and BPC21 - get importance levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GET importance levels for BPC21\n",
    "\n",
    "# combined_long_table,wide_format_table = getdemo_scaled(\"xpid3\",\"BPC21\",False)\n",
    "\n",
    "# # important = wide_format_table[(wide_format_table[\"Response\"]==\"Very important\")|(wide_format_table[\"Response\"]==\"Somewhat important\")]\n",
    "# important = wide_format_table[(wide_format_table[\"Response\"]==\"Very concerned\")|(wide_format_table[\"Response\"]==\"Somewhat concerned\")]\n",
    "\n",
    "# important = pd.DataFrame(important.groupby(\"Q_Text\").value_counts()).reset_index()\n",
    "\n",
    "# important = important[['Q_Text', 'Response', 'Overall']]\n",
    "# important = important.pivot_table(index=['Q_Text'], columns=['Response'], \n",
    "#                                                     values='Overall',\n",
    "#                                                     fill_value=0)\n",
    "\n",
    "# important.to_csv(directory+\"BPC21_important.csv\",index=True)\n",
    "\n",
    "# # GET importance levels for BPC3\n",
    "\n",
    "# combined_long_table,wide_format_table = getdemo_scaled(\"xpid3\",\"BPC3\",False)\n",
    "\n",
    "# important = wide_format_table[(wide_format_table[\"Response\"]==\"Very important\")|(wide_format_table[\"Response\"]==\"Somewhat important\")]\n",
    "# # important = wide_format_table[(wide_format_table[\"Response\"]==\"Very concerned\")|(wide_format_table[\"Response\"]==\"Somewhat concerned\")]\n",
    "\n",
    "# important = pd.DataFrame(important.groupby(\"Q_Text\").value_counts()).reset_index()\n",
    "\n",
    "# important = important[['Q_Text', 'Response', 'Overall']]\n",
    "# important = important.pivot_table(index=['Q_Text'], columns=['Response'], \n",
    "#                                                     values='Overall',\n",
    "#                                                     fill_value=0)\n",
    "\n",
    "# important.to_csv(directory+\"BPC3_important.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC - GET TWO DEMOS: AGE AND PID FOR QUESTION 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_counts(x):\n",
    "#     # x is a DataFrame of grouped values including the 'wts' column for weights\n",
    "#     total_weight = x['wts'].sum()\n",
    "#     return total_weight\n",
    "\n",
    "# q = \"BPC1\"\n",
    "# demo1 = 'age'\n",
    "# demo2 = 'xpid3'\n",
    "\n",
    "\n",
    "# # Assume demo1 and demo2 are your two demographic categories\n",
    "\n",
    "# # Extracting political party labels for both demographic categories\n",
    "# demo1_labels = dict(zip(codebook[codebook['question'] == demo1]['value'], codebook[codebook['question'] == demo1]['code']))\n",
    "# demo2_labels = dict(zip(codebook[codebook['question'] == demo2]['value'], codebook[codebook['question'] == demo2]['code']))\n",
    "\n",
    "# # Combining both sets of labels into a single dictionary for easier access later\n",
    "# demo_labels = {**demo1_labels, **demo2_labels}\n",
    "\n",
    "# # Filtering out the relevant rows from the codebook for BPCX responses remains the same\n",
    "# bpcx_codebook = codebook[codebook['question'].str.contains(q)]\n",
    "\n",
    "# # Creating a dictionary to map response values to their meanings also remains the same\n",
    "# value_to_meaning = dict(zip(bpcx_codebook['value'], bpcx_codebook['code']))\n",
    "\n",
    "# # List to hold the reshaped tables still needed\n",
    "# long_format_tables = []\n",
    "\n",
    "# # Iterate through each BPCX question as before\n",
    "# for question in data.filter(regex='^'+q+'_').columns:\n",
    "#     # Group by both 'demo1' and 'demo2' along with 'question', then apply the weighted counts calculation\n",
    "#     summary_table = data.groupby([demo1, demo2, question]).apply(weighted_counts).unstack()\n",
    "\n",
    "#     # Correctly setting levels for MultiIndex without using 'inplace'\n",
    "#     summary_table.index = summary_table.index.set_levels([summary_table.index.levels[0].map(demo1_labels.get),\n",
    "#                                                           summary_table.index.levels[1].map(demo2_labels.get)])\n",
    "    \n",
    "#     # Rename columns using the value_to_meaning dictionary remains the same\n",
    "#     summary_table = summary_table.rename(columns=value_to_meaning)\n",
    "\n",
    "#     # Reset index to make both demos columns. This is adjusted to accommodate both demographic categories.\n",
    "#     summary_table = summary_table.reset_index()\n",
    "\n",
    "#     # Melt the DataFrame to long format, adjusting id_vars to include both demographic categories\n",
    "#     melted = summary_table.melt(id_vars=[demo1, demo2], var_name='Response', value_name='Count')\n",
    "#     melted['Question'] = question\n",
    "\n",
    "#     # Replace the question shorthand remains the same\n",
    "#     melted['Q_Text'] = q_codebook.get(question, question)  # Fallback to question ID if not found\n",
    "\n",
    "#     # Append to the list remains the same\n",
    "#     long_format_tables.append(melted)\n",
    "\n",
    "# # Concatenate all the long format tables into one remains the same\n",
    "# combined_long_table = pd.concat(long_format_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove \"Other\" open-text responses\n",
    "# try:\n",
    "#     combined_long_table = combined_long_table[~combined_long_table[\"Question\"].str.contains(\"TEXT\")]\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# # Remove superfluous question text\n",
    "# try:\n",
    "#     combined_long_table[\"Q_Text\"] = combined_long_table[\"Q_Text\"].str.split(' --- ', expand=True)[1].fillna(combined_long_table[\"Q_Text\"])\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     combined_long_table.drop([\"Question\"], axis=1, inplace=True)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# combined_long_table[\"Response\"] = combined_long_table[\"Response\"].str.replace('NO TEXT', \"Selected\")\n",
    "\n",
    "# ##GET %s\n",
    "\n",
    "# # Group by both demos and 'Q_Text', then calculate the sum for each group\n",
    "# total_counts = combined_long_table.groupby([demo1, demo2, 'Q_Text'])['Count'].sum().reset_index(name='Total Count')\n",
    "\n",
    "# # Filter only 'Selected' responses and calculate the sum\n",
    "# selected_counts = combined_long_table[combined_long_table['Response'] == 'Selected'].groupby([demo1, demo2, 'Q_Text'])['Count'].sum().reset_index(name='Selected Count')\n",
    "\n",
    "# # Merge the total and selected counts on both demos and 'Q_Text'\n",
    "# merged_counts = pd.merge(total_counts, selected_counts, on=[demo1, demo2, 'Q_Text'])\n",
    "\n",
    "# # Calculate the percentage of 'Selected' for each combination of demo1 and demo2 and 'Q_Text'\n",
    "# merged_counts['Selected Percentage'] = (merged_counts['Selected Count'] / merged_counts['Total Count'] * 100)  # Convert to percentage\n",
    "\n",
    "# merged_counts.drop([\"Total Count\", \"Selected Count\"], axis=1, inplace=True)\n",
    "\n",
    "# # To handle the two-dimensional structure, you might need to pivot or reshape data differently.\n",
    "# # If you want to pivot to have a multi-level column structure for demos, you can do something like this:\n",
    "# merged_counts_pivot = merged_counts.pivot_table(index='Q_Text', columns=[demo1, demo2], values='Selected Percentage').reset_index()\n",
    "\n",
    "# # Get total responses by Q_Text\n",
    "# total_counts_by_qtext = combined_long_table.groupby(['Q_Text'])['Count'].sum().reset_index(name='Total Count')\n",
    "\n",
    "# # Calculate overall percentages\n",
    "# overall_percent = (combined_long_table[combined_long_table['Response'] == 'Selected'].groupby(['Q_Text'])['Count'].sum() / total_counts_by_qtext['Total Count'][0]).reset_index(name='Selected Percentage')\n",
    "\n",
    "# # Flatten the MultiIndex columns\n",
    "# # Convert MultiIndex columns to a simple index by joining level names with an underscore (or any other separator you prefer)\n",
    "# merged_counts_pivot.columns = ['_'.join(col).strip() for col in merged_counts_pivot.columns.values]\n",
    "# merged_counts_pivot.rename({\"Q_Text_\":\"Q_Text\"},axis=1,inplace=True)\n",
    "\n",
    "# # Now, both DataFrames should have a single-level column structure\n",
    "# # Merge the overall percentages with the demo-based percentages\n",
    "# final_merged_counts = pd.merge(merged_counts_pivot, overall_percent, on=['Q_Text'], how='left')\n",
    "\n",
    "# # Display the final merged table\n",
    "# display(final_merged_counts)\n",
    "\n",
    "\n",
    "# final_merged_counts.to_csv(directory+q+\"_age&xpid.csv\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
